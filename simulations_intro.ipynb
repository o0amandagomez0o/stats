{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations  = Monte Carlo\n",
    "\n",
    "## How to run a simulation with python/numpy/pandas\n",
    "1. Figure out a way to represent our data\n",
    "2. Create a matrix of random data, rows= simulations, columns = trial\n",
    "     - For Ex, rolling 2 dice 10,000 times means rows = 10000 and columns  = 2 b'c we roll 2 dice ea time\n",
    "3. Apply an aggregate function, row-wisde to get the results of the simulation\n",
    "4. Apply a final aggregate to get our probability.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ...,  True,  True, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's answer questions experimentally reather than theoretically\n",
    "# What's the prob of flipping HEADS on a coin?\n",
    "\n",
    "# let's flip a coin 100,000 times and figure our the prob of flipping HEADS\n",
    "\n",
    "# let's find a way to rep our data\n",
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "n_simulations = 100_000\n",
    "\n",
    "flips = np.random.choice(outcomes, size = n_simulations)\n",
    "\n",
    "# after flipping 100k coins, our experimentsal prob of flipping heads is:\n",
    "(flips == \"Heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49844"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.499538"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "n_simulations = 1_000_000\n",
    "\n",
    "flips = np.random.choice(outcomes, size = n_simulations)\n",
    "\n",
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another ex\n",
    "# what is the prob of rolling a 5 on a 6-sided die?\n",
    "\n",
    "#1. represent our data's outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. trials: create the data\n",
    "n_simulations = 10_000\n",
    "\n",
    "rolls = np.random.choice(outcomes, size=n_simulations)\n",
    "\n",
    "#what are the changes we roll a 5?\n",
    "(rolls == 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3382"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll a 5 or 6 on a 6-sided die?\n",
    "(rolls >= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll less than a 3 on a 6-sided die?\n",
    "(rolls < 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll anything other than 3 on a 6-sided die?\n",
    "(rolls != 3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's roll 2 dice at once\n",
    "1. figure out a way to rep the data\n",
    "2. create a matrix of random data, row=simulations, columns=trials\n",
    "3. apply an aggregate row-wise to get the result oif ea simulation\n",
    "4. apply a final aggregate (prob the .mean) to get out probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [3, 6],\n",
       "       [2, 3],\n",
       "       ...,\n",
       "       [4, 2],\n",
       "       [5, 4],\n",
       "       [6, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the odds of rolling Snake Eyes on 2 die?\n",
    "\n",
    "#1. rep our outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. create a matrix of randon data where rows=simulations, columns-trials\n",
    "\n",
    "#simulations = # of times we run the experiment\n",
    "# trials = # of things in ea experiment\n",
    "n_simulations = 1_000_000\n",
    "n_trials = 2# b'c we're rolling 2 dice with ea experiment\n",
    "\n",
    "#size arguement can set our simulation and trial size\n",
    "rolls = np.random.choice(outcomes, size=(n_simulations, n_trials))\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 9, 5, ..., 6, 9, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. apply an aggregate row-wise\n",
    "#axis=1 means sum across the rows\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "sum_of_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3498326, 3499122])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis=0::: COLUMNS\n",
    "#rolls.sum(axis=0)\n",
    "\n",
    "#if you don't put an axis, it defaults to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027678"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. apply a final aggregate\n",
    "(sum_of_rolls == 2).mean()\n",
    "\n",
    "#add up all the times an experiment/simulation produces the sum of two(Snake Eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our theoretical probability of rolling snake eyes is 1/6 * 1/6, which is 0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "theoretical = 1/6 * 1/6\n",
    "\n",
    "print(f\"Our theoretical probability of rolling snake eyes is 1/6 * 1/6, which is {theoretical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the prob of rolling a 7 on 2 die?\n",
    "# 1+6, 2+5, 3+4, 4+3, 5+2, 6+1 \n",
    "\n",
    "#1. rep out outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. generate matrix of random outcomes, simulations=rows, trials=columns\n",
    "#size=(simulations, trials)\n",
    "#sixe(experiments, number_of_dice per experi)\n",
    "\n",
    "rolls = np.random.choice(outcomes, size=(10_000, 2))\n",
    "\n",
    "#3. apply row-wise aggregate\n",
    "#axis=1, to apply sum to rows\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "\n",
    "(sum_of_rolls == 7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible sum outcomes from 2 die\n",
    "x = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "#\n",
    "y = [(sum_of_rolls == n).mean() for n in sum_of_rolls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0291,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.0258,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0258,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0291,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0291,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  5, 10,  4,  7,  3,  5,  8,  8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_rolls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0837, 0.1104, 0.1104, 0.0809, 0.0837, 0.168, 0.0544, 0.1104, 0.1413, 0.1413]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5446"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's answer questions experimentally reather than theoretically\n",
    "# What's the prob of flipping HEADS on a coin?\n",
    "\n",
    "# let's flip a coin 100,000 times and figure our the prob of flipping HEADS\n",
    "\n",
    "# let's find a way to rep our data\n",
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "\n",
    "flips = np.random.choice(outcomes, size=(10_000, 1), p=[0.55, 0.45])\n",
    "\n",
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Heads', 'Tails'],\n",
       "       ['Heads', 'Tails'],\n",
       "       ['Heads', 'Heads'],\n",
       "       ...,\n",
       "       ['Heads', 'Tails'],\n",
       "       ['Tails', 'Heads'],\n",
       "       ['Heads', 'Tails']], dtype='<U5')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what are the chances of flipping 2 heads in a row?\n",
    "flips = np.random.choice(outcomes, size=(10_000, 2), p=[0.55, 0.45])\n",
    "flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it'll be a bit easier to check for two heads if the head=1, and tail=0\n",
    "#might as well turn a binary into a binary\n",
    "\n",
    "#let's say heads is 1 and tails is 0\n",
    "outcomes =[1, 0]\n",
    "\n",
    "flips = np.random.choice(outcomes, size=(10_000, 2), p=[0.55, 0.45])\n",
    "flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis=1 to sum across the rows, so we have as many sums as we had pairs of coin flips\n",
    "num_of_heads = flips.sum(axis=1)\n",
    "len(num_of_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_of_heads == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3014"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_of_heads == 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2513"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what are the chances of flipping 2 heads in a row?\n",
    "\n",
    "#what if this was a fair coin?\n",
    "flips = np.random.choice(outcomes, size=(10_000, 2))\n",
    "num_of_heads = flips.sum(axis=1)\n",
    "(num_of_heads == 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52,   9,  86, ...,  15,  82, -29])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's add some boolean logic to probabilities\n",
    "\n",
    "#let's say we have an avg of 0 and a std of 20\n",
    "\n",
    "numbers = np.random.randint(-50, 100, 100_000)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3315"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#based on these simulations, what is the probability that any number is negative?\n",
    "(numbers< 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob that the number is odd?\n",
    "(numbers % 2 !=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob of a number being both odd and neg?\n",
    "is_negative = (numbers < 0)\n",
    "is_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ...,  True, False,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_odd = (numbers % 2 != 0)\n",
    "is_odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16533"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob of a number being both odd and neg?\n",
    "(is_odd & is_negative).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16533"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((numbers < 0) & (numbers % 2 !=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83467"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob of your number being even OR positive?\n",
    "((numbers > 0) | (numbers % 2 ==0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_even = (numbers % 2 ==0)\n",
    "is_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_positive = (numbers > 0)\n",
    "is_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83467"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(is_even | is_positive).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 6, 3, ..., 3, 2, 2]), array([3, 3, 5, ..., 6, 2, 6]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rolling 2 dice at a time, what is the prob of rolling an odd and then an even #?\n",
    "\n",
    "#1. rep the world in Pandas/Numpy\n",
    "first_die = np.random.choice([1, 2, 3, 4, 5, 6], size=100_000)\n",
    "second_die = np.random.choice([1, 2, 3, 4, 5, 6], size=100_000)\n",
    "\n",
    "first_die, second_die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True, False, False])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need to rep the results of the 1st die as an array of booleans\n",
    "first_die % 2 != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_die_is_odd = (first_die % 2 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_die_is_even = (second_die % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_odd_second_even = (first_die_is_odd & second_die_is_even)\n",
    "first_odd_second_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24864"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_odd_second_even.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#theoretical probability\n",
    "0.5 * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
