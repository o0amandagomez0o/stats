{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations  = Monte Carlo\n",
    "\n",
    "## How to run a simulation with python/numpy/pandas\n",
    "1. Figure out a way to represent our data\n",
    "2. Create a matrix of random data, rows= simulations, columns = trial\n",
    "     - For Ex, rolling 2 dice 10,000 times means rows = 10000 and columns  = 2 b'c we roll 2 dice ea time\n",
    "3. Apply an aggregate function, row-wisde to get the results of the simulation\n",
    "4. Apply a final aggregate to get our probability.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ...,  True,  True, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's answer questions experimentally reather than theoretically\n",
    "# What's the prob of flipping HEADS on a coin?\n",
    "\n",
    "# let's flip a coin 100,000 times and figure our the prob of flipping HEADS\n",
    "\n",
    "# let's find a way to rep our data\n",
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "n_simulations = 100_000\n",
    "\n",
    "flips = np.random.choice(outcomes, size = n_simulations)\n",
    "\n",
    "# after flipping 100k coins, our experimentsal prob of flipping heads is:\n",
    "(flips == \"Heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49844"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.499538"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "n_simulations = 1_000_000\n",
    "\n",
    "flips = np.random.choice(outcomes, size = n_simulations)\n",
    "\n",
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another ex\n",
    "# what is the prob of rolling a 5 on a 6-sided die?\n",
    "\n",
    "#1. represent our data's outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. trials: create the data\n",
    "n_simulations = 10_000\n",
    "\n",
    "rolls = np.random.choice(outcomes, size=n_simulations)\n",
    "\n",
    "#what are the changes we roll a 5?\n",
    "(rolls == 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3382"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll a 5 or 6 on a 6-sided die?\n",
    "(rolls >= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll less than a 3 on a 6-sided die?\n",
    "(rolls < 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the prob we'll roll anything other than 3 on a 6-sided die?\n",
    "(rolls != 3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's roll 2 dice at once\n",
    "1. figure out a way to rep the data\n",
    "2. create a matrix of random data, row=simulations, columns=trials\n",
    "3. apply an aggregate row-wise to get the result oif ea simulation\n",
    "4. apply a final aggregate (prob the .mean) to get out probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [3, 6],\n",
       "       [2, 3],\n",
       "       ...,\n",
       "       [4, 2],\n",
       "       [5, 4],\n",
       "       [6, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the odds of rolling Snake Eyes on 2 die?\n",
    "\n",
    "#1. rep our outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. create a matrix of randon data where rows=simulations, columns-trials\n",
    "\n",
    "#simulations = # of times we reun the experiment\n",
    "# trials = # of things in ea experiment\n",
    "n_simulations = 1_000_000\n",
    "n_trials = 2# b'c we're rolling 2 dice with ea experiment\n",
    "\n",
    "#size arguement can set our simulation and trial size\n",
    "rolls = np.random.choice(outcomes, size=(n_simulations, n_trials))\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 9, 5, ..., 6, 9, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. apply an aggregate row-wise\n",
    "#axis=1 means sum across the rows\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "sum_of_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3498326, 3499122])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis=0::: COLUMNS\n",
    "#rolls.sum(axis=0)\n",
    "\n",
    "#if you don't put an axis, it defaults to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027678"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. apply a final aggregate\n",
    "(sum_of_rolls == 2).mean()\n",
    "\n",
    "#add up all the times an experiment/simulation produces the sum of two(Snake Eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our theoretical probability of rolling snake eyes is 1/6 * 1/6, which is 0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "theoretical = 1/6 * 1/6\n",
    "\n",
    "print(f\"Our theoretical probability of rolling snake eyes is 1/6 * 1/6, which is {theoretical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the prob of rolling a 7 on 2 die?\n",
    "# 1+6, 2+5, 3+4, 4+3, 5+2, 6+1 \n",
    "\n",
    "#1. rep out outcomes\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#2. generate matrix of random outcomes, simulations=rows, trials=columns\n",
    "#size=(simulations, trials)\n",
    "#sixe(experiments, number_of_dice per experi)\n",
    "\n",
    "rolls = np.random.choice(outcomes, size=(10_000, 2))\n",
    "\n",
    "#3. apply row-wise aggregate\n",
    "#axis=1, to apply sum to rows\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "\n",
    "(sum_of_rolls == 7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible sum outcomes from 2 die\n",
    "x = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "#\n",
    "y = [(sum_of_rolls == n).mean() for n in sum_of_rolls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0291,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.0258,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0291,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.0258,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.0258,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.0567,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0291,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.0291,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1154,\n",
       " 0.0567,\n",
       " 0.0809,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.0837,\n",
       " 0.0258,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0567,\n",
       " 0.1413,\n",
       " 0.0544,\n",
       " 0.0291,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.0291,\n",
       " 0.1154,\n",
       " 0.0809,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.0837,\n",
       " 0.168,\n",
       " 0.0567,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0258,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.0544,\n",
       " 0.0809,\n",
       " 0.1413,\n",
       " 0.0567,\n",
       " 0.1343,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1413,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1343,\n",
       " 0.0258,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.0567,\n",
       " 0.0291,\n",
       " 0.0809,\n",
       " 0.0809,\n",
       " 0.0837,\n",
       " 0.0837,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.0258,\n",
       " 0.168,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.168,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1104,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1413,\n",
       " 0.0809,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1343,\n",
       " 0.1104,\n",
       " 0.0837,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " 0.168,\n",
       " 0.0544,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.0837,\n",
       " 0.1104,\n",
       " 0.1413,\n",
       " 0.1154,\n",
       " 0.1413,\n",
       " 0.1104,\n",
       " 0.0544,\n",
       " 0.1343,\n",
       " 0.1154,\n",
       " 0.168,\n",
       " 0.1154,\n",
       " 0.1343,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
